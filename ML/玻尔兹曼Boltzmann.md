# 玻尔兹曼Boltzmann

### 物理上和统计上的玻尔兹曼分布

​	热平衡在物理学领域通常指温度在**时间或空间上的稳定**。在统计学习中，如果我们将需要学习的模型看成**高温物体**，将学习的过程看成**一个降温达到热平衡的过程**，最终模型的能量将会收敛为一个分布，并且在全局极小能量上下波动。这个过程称为“模拟退火”。而**模型能量收敛到的分布**称为玻尔兹曼分布（Boltzmann Distribution）



### 玻尔兹曼机

##### 定义

玻尔兹曼分布在机器学习模型的设计中被广泛采用，我们就从玻尔兹曼机（Boltzmann Machine）说起。

玻尔兹曼机是一个对称连接的神经网络。它用于决定系统的状态是开（1）还是关（0）。玻尔兹曼机可以看成一个通过无向有权边全连接的网络。这个网络的能量函数定义为 

> E=−(∑i<jwijsisj+∑iθisi)E=−(∑i<jwijsisj+∑iθisi)

 其中

- wijwij是连接节点ii和jj的权重。
- sisi是节点ii的状态，且si∈{0,1}si∈{0,1}。
- θiθi是节点ii的在全局能量函数中的偏倚。也就是说−θi−θi是节点ii的激活阈值。

单个节点ii的能量定义为 

> Ei=θi+∑jwijsj



玻尔兹曼机单个节点ii状态从00变为11造成的网络能量变化为 

> ΔEi=∑j>iwijsj+∑j<iwjisj+θiΔEi=∑j>iwijsj+∑j<iwjisj+θi





### RBM模型结构(restricted boltzmann machine)

　　　　玻尔兹曼机是一大类的神经网络模型，但是在实际应用中使用最多的则是RBM。RBM本身模型很简单，只是一个两层的神经网络，因此严格意义上不能算深度学习的范畴。不过深度玻尔兹曼机（Deep Boltzmann Machine，以下简称DBM）可以看做是RBM的推广。理解了RBM再去研究DBM就不难了，因此本文主要关注于RBM。



### RBM在实际中应用方法

　　　　大家也许会疑惑，这么一个模型在实际中如何能够应用呢？比如在推荐系统中是如何应用的呢？这里概述下推荐系统中使用的常用思路。

　　　　RBM可以看做是一个编码解码的过程，从可见层到隐藏层就是编码，而反过来从隐藏层到可见层就是解码。在推荐系统中，我们可以把每个用户对各个物品的评分做为可见层神经元的输入，然后有多少个用户就有了多少个训练样本。由于用户不是对所有的物品都有评分，所以任意样本有些可见层神经元没有值。但是这不影响我们的模型训练。在训练模型时，对于每个样本，我们仅仅用有用户数值的可见层神经元来训练模型。

　　　　对于可见层输入的训练样本和随机初始化的W,aW,a,我们可以用上面的sigmoid激活函数得到隐藏层的神经元的0,1值，这就是编码。然后反过来从隐藏层的神经元值和W,bW,b可以得到可见层输出，这就是解码。对于每个训练样本， 我们期望编码解码后的可见层输出和我们的之前可见层输入的差距尽量的小，即上面的对数似然损失函数尽可能小。按照这个损失函数，我们通过迭代优化得到W,a,bW,a,b，然后对于某个用于那些没有评分的物品，我们用解码的过程可以得到一个预测评分，取最高的若干评分对应物品即可做用户物品推荐了。

> RBM很容易推广到深层的RBM，即我们的DBM(deep belif machine。推广的方法就是加入更多的隐藏层



### **深度信念网络**DBM

　　深度信念网络是一个概率生成模型，与传统的判别模型的神经网络相对，生成模型是建立一个观察数据和标签之间的联合分布，对P(Observation|Label)和 P(Label|Observation)都做了评估，而判别模型仅仅而已评估了后者，也就是P(Label|Observation)。

　　DBNs由多个限制玻尔兹曼机（Restricted Boltzmann Machines）层组成，一个典型的网络结构如图1所示。这些网络被“限制”为一个可视层和一个隐层，层间存在连接，但层内的单元间不存在连接。隐层单元被训练去捕捉在可视层表现出来的高阶数据的相关性。

