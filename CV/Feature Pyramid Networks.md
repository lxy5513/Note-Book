# Feature Pyramid Networks  

## 1. Motivation 

​	在做objection detection时，一般只能对同一尺寸的图片进行网络训练，我们希望我们的==网络可以适应更多尺寸的图片==

​	传统使用图像金字塔，但提升了图片的复杂度。  

> 传统的图像金字塔任务是将不同尺度的图片进行特征提取（图a），主要使用人工提取特征，在人工提取特征的时代，大量使用特征化图像金字塔。它们非常重要，以至于像DPM这样的物体检测器需要密集的比例采样才能获得好的结果。但是这种做法变相的增加了训练数据，提高了运算耗时，所以这种做法已经很少被使用。

为了改善这个：

​		使用FPN

![](/Users/liuxingyu/Pictures/markdown/fpn.jpg)

对于识别任务，工程特征已经被深度卷积网络（ConvNets）计算的特征大部分所取代。除了能够表示更高级别的语义，ConvNets不同层的特征图尺度也不同，从而有助于从单一输入尺度上计算的特征识别（图b）。但是这种做法的缺陷在于**只使用了高分辨率特征**，因为不同层之间的语义差别很大，最后一层主要都是高分辨率的特征，所以对于低分辨率的特征表现力不足。

接着为了改善上面的做法，一个很简洁的改进就是**对不同尺度的特征图都进行利用**，这也是SSD算法中使用的方法（图c）。理想情况下，SSD(Single Shot MultiBox Detector)风格的金字塔将重复使用正向传递中计算的不同层次的多尺度特征图。但为了避免使用低层次特征，SSD会从偏后的conv4_3开始构建特征金字塔，这种做法**没有对conv4_3之前的层进行利用**，而这些层对于检测小目标很重要。

![](/Users/liuxingyu/Pictures/markdown/fpn1.jpg)

本文提出一种新的做法（图d），通过高层特征进行上采样和低层特征进行自顶向下的连接，而且每一层都会进行预测 . 不是对不同尺寸的特征图进行预测，而是将==不同尺寸的特征图融合后进行预测==。

![](/Users/liuxingyu/Pictures/markdown/fpn2.jpg)



作为特征提取器。底层检测的是低级特征（边缘和角等），较高层检测的是更高级的特征（汽车、人、天空等）

# 网络结构

主网络是使用的`ResNet`，而特征图金字塔分成三个部分，一个**自底向上的路径**（左边），一个**自顶向下的路径**（右边）和**中间的连接**部分。

![](/Users/liuxingyu/Pictures/markdown/fpn3.jpg)



 ![](/Users/liuxingyu/Pictures/markdown/fpnet.jpg)



**自底向上的路径**：自下而上的路径是卷积网络的前馈计算，该算法计算由不同比例的特征映射组成的特征层级，其缩放步长为2。通常由许多层产生相同大小的输出映射，并且说这些层处于相同的网络阶段。为每一个阶段定义一个金字塔等级，然后选择每个阶段的最后一层的输出作为我们特征图的参考集（每个阶段最深层应具有最强的特征）

> 具体而言，对于ResNets，我们使用每个阶段的最后一个residual block输出的特征激活输出。 对于conv2，conv3，conv4和conv5输出，我们将这些最后residual block的输出表示为{C2，C3，C4，C5}，并且它们相对于输入图像具有{4, 8, 16, 32} 的步长。 由于其庞大的内存占用，我们不会将conv1纳入金字塔中。

**自顶向下的路径**：自顶向下的路径通过对在空间上更抽象但语义更强高层特征图进行upsample来幻化高分辨率特征 随后通过侧向连接从底向上的路径，是高层特征得到增强。每个横向连接的特征图具有相同的尺寸。将低分辨率的图做2倍上采样。然后通过按元素相加，同层映射合并。

> 为了开始迭代，我们只需在C5上附加一个1×1卷积层来生成低分辨率图P5。最后，我们在每个合并的图上附加一个3×3卷积来生成最终的特征映射，这是为了减少上采样的混叠效应。这个最终的特征映射集称为{P2，P3，P4，P5}，分别对应于{C2，C3，C4，C5}，它们具有相同的尺寸。 
>
> 由于金字塔的所有层次都像传统的特征化图像金字塔一样使用共享分类器/回归器，因此我们在所有特征图中固定特征维度（通道数，记为d）。我们在本文中设置d = 256，因此所有额外的卷积层都有256个通道的输出

![](/Users/liuxingyu/Pictures/markdown/fpn4.jpg)

**中间连接**：采用`1×1`的卷积核进行连接（减少特征图数量）

### Usage

Mask RCNN 中自底向上的网络结构，为上述介绍的 ResNet50/101，对应的特征图为 [Stage2,Stage3,Stage4,Stage5]，自顶向下的网络结构，把上采样的结果和上层 Stage 的特征图进行元素相加操作，生成新的特征图 [P2, P3, P4, P5, P6], 如下所示：

P5 对应 C5

P4 对应 C4+ UpSampling2D（P5）

P3 对应 C4+ UpSampling2D（P4）

P2 对应 C4+ UpSampling2D（P3）

P6 对应 MaxPooling2D(strides=2) (P5)

这样最后生成的 FPN 特征图集合为 [P2,P3,P4,P5,P6]，每个特征图对应的 Stride 为 [4, 8, 16, 32,64]，对应的特征图大小为 [256*256,128*128,64*64,32*32，16*16]，对应的 anchor 大小为 [32, 64, 128, 256, 512]，这样==底层的特征图用于去检测较小的目标，高层的特征图用于去检测较大的目标。==

<!--anchor 有什么作用？     生成的特征图集合独自应用到下一层吗？     -->. 

### Problem

从不同level取feature做roipooling后需要分类和回归，这些各个level需要共享吗？要是共享，如何共享