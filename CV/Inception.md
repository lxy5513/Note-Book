## Inception

如果 ResNet 是为了更深，那么 Inception 家族就是为了**更宽**。Inception 的作者对训练更大型网络的计算效率尤其感兴趣。换句话说：我们==怎样在不增加计算成本的前提下扩展神经网络==？

Inception 最早的论文关注的是一种用于深度网络的新型构建模块，现在这一模块被称为「Inception module」。究其核心，这种模块源自两种思想见解的交汇。

第一个见解与对层的操作有关。在传统的卷积网络中，每一层都会从之前的层提取信息，以便将输入数据转换成更有用的表征。但是，不同类型的层会提取不同种类的信息。5×5 卷积核的输出中的信息就和 3×3 卷积核的输出不同，又不同于最大池化核的输出……**在任意给定层**，**我们怎么知道什么样的变换能提供最「有用」的信息呢？**

#### 见解 1：为什么不让模型选择？

Inception 模块会并行计算同一输入映射上的多个不同变换，并将它们的结果都连接到单一一个输出。换句话说，对于每一个层，Inception 都会执行 5×5 卷积变换、3×3 卷积变换和最大池化。然后该模型的下一层会决定是否以及怎样使用各个信息。

![](/Users/liuxingyu/Pictures/markdown/inception.png)

这种模型架构的信息密度更大了，这就带来了一个突出的问题：**计算成本大大增加。**不仅**大型（比如 5×5）卷积过滤器的固有计算成本高**，并**排堆叠多个不同的过滤器更会极大增加每一层的特征映射的数量**。而这种计算成本增长就成为了我们模型的致命瓶颈。

「过滤器数量的任何统一增长都会导致计算量的 4 倍增长。」

想一下，每额外增加一个过滤器，我们就必须对所有输入映射进行卷积运算以计算单个输出。如下图所示：从单个过滤器创建一个输出映射涉及到在之前一层的每个单个映射上执行计算。

#### 见解 2: 先使特征映射降维

使用 1×1 卷积来执行降维。为了解决上述计算瓶颈，Inception 的作者使用了 1×1 卷积来「过滤」输出的深度。一个 1×1 卷积一次仅查看一个值，但在多个通道上，它可以提取空间信息并将其压缩到更低的维度。比如，**使用 20 个 1×1 过滤器**，一个大小为 64×64×100（具有 100 个特征映射）的输入可以被压缩到 64×64×20==（why？ 滤波器数量就代表输出层的深度 池化层只能改变维度）==（每一个滤波器都可以把一百层变成一层吗？）。通过减少输入映射的数量，Inception 可以将不同的层变换并行地堆叠到一起，从而得到既深又宽（很多并行操作）的网络。

![](/Users/liuxingyu/Pictures/markdown/inception1.png)

这能达到多好的效果？Inception 的第一个版本是 GoogLeNet，也就是前面提及的赢得了 ILSVRC 2014 比赛的 22 层网络。一年之后，研究者在第二篇论文中发展出了 Inception v2 和 v3，并在原始版本上实现了多种改进——其中最值得一提的是将更大的卷积重构成了连续的更小的卷积，让学习变得更轻松。比如在 v3 中，5×5 卷积被替换成了两个 连续的 3×3 卷积。

Inception 很快就变成了一种具有决定性意义的模型架构。最新的版本 Inception v4 甚至将残差连接放进了每一个模组中，创造出了一种 Inception-ResNet 混合结构。但更重要的是，Inception 展现了经过良好设计的「网中有网」架构的能力，让神经网络的表征能力又更上了一层楼。



### Xception

Xception 表示「extreme inception」。和前面两种架构一样，它重塑了我们看待神经网络的方式——尤其是卷积网络。而且正如其名字表达的那样，它将 Inception 的原理推向了极致。

它的假设是：**==「跨通道的相关性和空间相关性是完全可分离的，最好不要联合映射它们。」==**

这是什么意思？在传统的卷积网络中，卷积层会同时寻找跨空间和跨深度的相关性。让我们再看一下标准的卷积层：

![](/Users/liuxingyu/Pictures/markdown/conv.png)

在上图中，过滤器同时考虑了一个空间维度（每个 2×2 的彩色方块）和一个跨通道或「深度」维度（4 个方块的堆叠）。在输入图像的输入层，这就相当于一个在所有 3 个 RGB 通道上查看一个 2×2 像素块的卷积过滤器。那问题来了：**我们有什么理由去同时考虑图像区域和通道？**

在 Inception 中，我们开始将两者稍微分开。**我们使用 1×1 的卷积将原始输入投射到多个分开的更小的输入空间**，而且对于其中的每个输入空间，我们都使用一种不同类型的过滤器来对这些数据的更小的 3D 模块执行变换。Xception 更进一步。不再只是将输入数据分割成几个压缩的数据块，而是==为每个输出通道单独映射空间相关性==，然后再执行 1×1 的深度方面的卷积来获取跨通道的相关性。

![](/Users/liuxingyu/Pictures/markdown/xinception.png)

其作者指出这本质上相当于一种已有的被称为「**深度方面可分的卷积（depthwise separable convolution）**」的运算，它包含一个深度方面的卷积（一个为每个通道单独执行的空间卷积），后面跟着一个逐点的卷积（一个跨通道的 1×1 卷积）。**我们可以将其看作是首先求跨一个 2D 空间的相关性，然后再求跨一个 1D 空间的相关性**。可以看出，这种 2D+1D 映射学起来比全 3D 映射更加简单。

而且这种做法是有效的！在 ImageNet 数据集上，Xception 的表现稍稍优于 Inception v3，而且在一个有 17000 类的更大规模的图像分类数据集上的表现更是好得多。最重要的是，它的模型参数的数量和 Inception 一样多，说明它的计算效率也更高。