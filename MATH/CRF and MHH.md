# CRF and MHH



## 作用

> 为了让我们的分类器能够有更好的表现，在为一张照片分类时，我们必须将与它相邻的照片的标签信息考虑进来。这——就是条件随机场(CRF)大显身手的地方



## Prerequisite

> 只研究标注模型

#### **马尔科夫假设&马尔科夫性**

**1. 马尔科夫假设**

应该是齐次马尔科夫假设，这样假设：马尔科夫链 ![(x_{1},\cdots,x_{n})](https://www.zhihu.com/equation?tex=%EF%BC%88x_%7B1%7D%2C%5Ccdots%2Cx_%7Bn%7D%29) 里的 **![ x_{i}](https://www.zhihu.com/equation?tex=+x_%7Bi%7D) 总是只受 ![ x_{i-1}](https://www.zhihu.com/equation?tex=+x_%7Bi-1%7D) 一个人的影响**。
马尔科夫假设这里相当于就是个1-gram。

马尔科夫过程呢？即，在一个过程中，每个状态的转移只依赖于前n个状态，并且只是个n阶的模型。最简单的马尔科夫过程是一阶的，即只依赖于器哪一个状态。

**2. 马尔科夫性**

马尔科夫性是是保证或者判断概率图是否为**概率无向图**的条件。

三点内容：a. 成对，b. 局部，c. 全局。

#### **序列建模**

为了号召零门槛理解，现在解释如何为序列问题建模。

![](/Users/liuxingyu/Pictures/markdown/sequence.jpg)

序列包括时间序列以及general sequence，但两者无异。连续的序列在分析时也会先离散化处理。常见的序列有如：时序数据、本文句子、语音数据、等等。

广义下的序列有这些特点：

- 节点之间有关联依赖性/无关联依赖性
- 序列的节点是随机的/确定的
- 序列是线性变化/非线性的

对不同的序列有不同的问题需求，常见的序列建模方法总结有如下：

1. 拟合，预测未来节点（或走势分析）：

   > a. 常规序列建模方法：AR、MA、ARMA、ARIMA
   >
   >  b. 回归拟合
   >
   >   c. Neural Networks

2. 判断不同序列类别，

   > 即分类问题：HMM、CRF、General Classifier（ML models、NN models）

3. 不同时序对应的状态的分析

   > 即序列标注问题：HMM、CRF、RecurrentNNs

在本篇文字中，我们只关注在2. & 3.类问题下的建模过程和方法。



## CRF

### 例子

##### 啥是词性标注问题？

> 非常简单的，就是给一个句子中的每个单词注明词性。比如这句话：“Bob drank coffee at Starbucks”，注明每个单词的词性后是这样的：“Bob (名词)  drank(动词)   coffee(名词)   at(介词)    Starbucks(名词)”。
>
> 下面，就用条件随机场来解决这个问题。
>
> 以上面的话为例，有5个单词，我们将：**(名词，动词，名词，介词，名词)**作为一个标注序列，称为l，可选的标注序列有很多种，比如l还可以是这样：**（名词，动词，动词，介词，名词）**，我们要在这么多的可选标注序列中，挑选出一个**最靠谱**的作为我们对这句话的标注。

##### 怎么判断一个标注序列靠谱不靠谱呢？

> 就我们上面展示的两个标注序列来说，第二个显然不如第一个靠谱，因为它把第二、第三个单词都标注成了动词，动词后面接动词，这在一个句子中通常是说不通的。
>
> 假如我们给每一个标注序列打分，打分越高代表这个标注序列越靠谱，我们至少可以说，凡是标注中出现了**动词后面还是动词**的标注序列，要给它**负分！！**

上面所说的**动词后面还是动词**就是一个==特征函数==，我们可以定义一个特征函数集合，用这个**特征函数集合来为一个标注序列打分**，并据此选出最靠谱的标注序列。也就是说，每一个特征函数都可以用来为一个标注序列评分，把集合中所有特征函数对同一个标注序列的评分综合起来，就是这个标注序列最终的评分值。



### 定义CRF中的特征函数

现在，我们正式地定义一下什么是CRF中的特征函数，所谓特征函数，就是这样的函数，它接受四个参数：

> - 句子s（就是我们要标注词性的句子）
> - i，用来表示句子s中第i个单词
> - $l_i$，表示要评分的标注序列给第i个单词标注的词性
> - $l_{i-1}$，表示要评分的标注序列给第i-1个单词标注的词性

它的输出值是0或者1,         0表示要评分的标注序列不符合这个特征，1表示要评分的标注序列符合这个特征。

> **Note:**这里，我们的特征函数**仅仅依靠当前单词的标签和它前面的单词的标签对标注序列进行评判**，这样建立的CRF也叫作线性链CRF，这是CRF中的一种简单情况。为简单起见，本文中我们仅考虑线性链CRF。

​															<!--特征函数是仅仅两个单词-->

### 从特征函数到概率

定义好一组特征函数后，我们要给每个特征函数$f_j$赋予一个权重$λ_j$。现在，只要有一个句子$s$，有一个标注序列l，我们就可以利用前面定义的特征函数集来对$l$评分。

**$score(l|s) = \sum_{j=1}^m\sum_{i=1}^n\lambda_jf_j(s,i,l_i,l_{i-1})$**

> n: the number of s
>
> m: the numbers of feature function

上式中有两个求和，外面的求和用来求每一个特征函数$f_j$评分值的和，里面的求和用来求句子中每个位置的单词的的特征值的和。



对这个分数进行**指数化和标准化**，我们就可以得到标注序列l的概率值**p(l|s)**，如下所示：

![](/Users/liuxingyu/Pictures/markdown/math1.png)

### 几个特征函数的例子

前面我们已经举过特征函数的例子，下面我们再看几个具体的例子，帮助增强大家的感性认识。

$f_1(s, i, l_i, l_{i-1}) = 1$

当$l_i$是“副词”并且第i个单词以“ly”结尾时，我们就让$f_1$ = 1，==其他情况$f_1$为0==。不难想到，f1特征函数的权重λ1应当是正的。

而且λ1越大，表示我们越倾向于采用那些把以“ly”结尾的单词标注为“副词”的标注序列

<!--**即 l_i是副词的概率是非常高的**-->



$f_2(s, i, l_i, l_{i-1}) = 1$

如果i=1，l_i=动词，并且句子s是以“？”结尾时，f2=1，其他情况f2=0。同样，λ2应当是正的，并且**λ2越大，表示我们越倾向于**采用那些把问句的第一个单词标注为“动词”的标注序列。



$f_3(s, i, l_i, l_{i-1}) = 1$ 

当$l_{i-1}$是介词，$l_i$是名词时，f3 = 1，其他情况f3=0。λ3也应当是正的，并且**λ3越大，说明我们越认为**介词后面应当跟一个名词。



$f_3(s, i, l_i, l_{i-1}) = 1$

如果$l_i$和$l_{i-1}$都是介词，那么f4等于1，其他情况f4=0。这里，我们应当可以想到λ4是负的，并且λ4的绝对值越大，表示我们越不认可介词后面还是介词的标注序列。

好了，一个条件随机场就这样建立起来了，让我们总结一下：
 为了建一个条件随机场，我们首先要定义一个特征函数集，每个特征函数都以整个句子s，当前位置i，位置i和i-1的标签为输入。然后为每一个特征函数赋予一个权重，然后针对每一个标注序列l，对所有的特征函数加权求和，必要的话，可以把求和的值转化为一个概率值。





## HMM(Hide Markov Model)

#### 前提

##### Markov property

> ###### 下一状态的概率分布只能由当前状态决定，在时间序列中它前面的事件均与之无关。这种特定类型的“无记忆性”称作马尔可夫性质

##### Markov process

> 马尔可夫过程的[条件概率](https://zh.wikipedia.org/wiki/%E6%9D%A1%E4%BB%B6%E6%A6%82%E7%8E%87)仅仅与系统的当前状态相关，而与它的过去历史或未来状态，都是[独立](https://zh.wikipedia.org/wiki/%E7%B5%B1%E8%A8%88%E7%8D%A8%E7%AB%8B%E6%80%A7)、不相关的

##### Markov chian

> 具备离散状态的马尔可夫过程，通常被称为马尔可夫链。马尔可夫链通常使用离散的时间集合定义



> ![img](https://upload.wikimedia.org/wikipedia/commons/thumb/d/d5/Hmm.png/300px-Hmm.png)
>
> 隐马尔可夫模型状态变迁图（例子）
> *x* — 隐含状态时间点![t](https://wikimedia.org/api/rest_v1/media/math/render/svg/65658b7b223af9e1acc877d848888ecdb4466560)的隐藏条件和时间点![t-1](https://wikimedia.org/api/rest_v1/media/math/render/svg/a215d9553945bb84b3b5a79cc796fb7d6e0629f0)的隐藏条件有关
> *y* — 可观察的输出
> *a* — 转换概率（transition probabilities）
> *b* — 输出概率（output probabilities）
>
> **隐马尔可夫模型**（Hidden Markov Model，HMM）是[统计](https://zh.wikipedia.org/wiki/%E7%BB%9F%E8%AE%A1)[模型](https://zh.wikipedia.org/wiki/%E6%A8%A1%E5%9E%8B)，它用来描述一个含有隐含未知参数的[马尔可夫过程](https://zh.wikipedia.org/wiki/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E8%BF%87%E7%A8%8B)。其难点是从可观察的参数中确定该过程的隐含参数。然后利用这些参数来作进一步的分析，例如[模式识别](https://zh.wikipedia.org/wiki/%E6%A8%A1%E5%BC%8F%E8%AF%86%E5%88%AB)。
>
> 在**正常**的马尔可夫模型中，状态对于观察者来说是直接可见的。这样状态的转换概率便是全部的参数。而在**隐**马尔可夫模型中,状态并不是直接可见的，但受状态影响的某些变量则是可见的。每一个状态在可能输出的符号上都有一[概率分布](https://zh.wikipedia.org/wiki/%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83)。因此输出符号的序列能够透露出状态序列的一些信息。

#### 例子

> 假设你有一个住得很远的朋友，他每天跟你打电话告诉你他那天做了什么。你的朋友仅仅对三种活动感兴趣：公园散步，购物以及清理房间。他选择做什么事情只凭天气。你对于他所住的地方的天气情况并不了解，但是你知道总的趋势。在他告诉你每天所做的事情基础上，你想要==猜测他所在地的天气情况==。

你认为天气的运行就像一个[马尔可夫链](https://zh.wikipedia.org/wiki/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E9%93%BE).其有两个状态 "雨"和"晴",但是你无法直接观察它们,也就是说,它们对于你是隐藏的。每天，你的朋友有一定的概率进行下列活动:"散步"、"购物"、"清理"。因为你朋友告诉你他的活动，所以这些活动就是你的观察数据。这整个系统就是一个隐马尔可夫模型HMM。

> #### 语音处理上的应用
>
> 因为马可夫模型有下列特色：
>
> - 时间 $t$ 的隐藏条件和时间点 $t-1$ 的隐藏条件有关。因为人类语音拥有前后的关联，可以从语义与发音两点来看：
>   - 单字的发音拥有前后关联：例如"They are"常常发音成"They're"，或是"Did you"会因为"you"的发音受"did"的影响，常常发音成"did ju"，而且语音辨识中用句子的发音来进行分析，因此需要考虑到每个音节的前后关系，才能够有较高的准确率。
>   - 句子中的单字有前后关系：从英文文法来看，主词后面常常接助动词或是动词，动词后面接的会是受词或介系词。而或是从单一单字的使用方法来看，对应的动词会有固定使用的介系词或对应名词。因此分析语音讯息时需要为了提升每个单字的准确率，也需要分析前后的单字

### 

## CRF vs HMM

#### 区别：

CRF is discriminative model  and undirected graph model

HMM is generative model and directed graph model

> CRF比HMM要强大的多，它可以解决所有HMM能够解决的问题，并且还可以解决许多HMM解决不了的问题

CRF要比HMM更加强大，原因主要有两点：

-  **CRF可以定义数量更多，种类更丰富的特征函数**。HMM模型具有天然具有局部性，就是说，在HMM模型中，==当前的单词只依赖于当前的标签，当前的标签只依赖于前一个标签==。这样的局部性限制了HMM只能定义相应类型的特征函数，我们在上面也看到了。但是==CRF却可以着眼于整个句子s定义更具有全局性的特征函数==，如这个特征函数：

> $f_2(s, i, l_i, l_{i-1}) = 1$
>
> 如果i=1，$l_i$=动词，并且句子s是以“？”结尾时，f2=1，其他情况f2=0。

- CRF可以使用任意的权重 

  将对数HMM模型看做CRF时，特征函数的权重由于是log形式的概率，所以都是小于等于0的，而且概率还要满足相应的限制，如

  $0 \leq p(w_i|l_i) \leq 1, \sum_wp(w_i=w|l_i) = 1$

  但在CRF中，每个特征函数的权重可以是任意值，没有这些限制。

