## 统计概率图（probability graph models）

#### Structure

![](/Users/liuxingyu/Pictures/markdown/probabilitygraph.jpg)



在概率图模型中，数据(样本)由公式 $G = (V, E)$ 建模表示： 

- $V$ 表示节点，即随机变量（放在此处的，可以是一个token或者一个label），具体地，用 ![Y = (y_{1}, {\cdots}, y_{n} ) ](https://www.zhihu.com/equation?tex=Y+%3D+%28y_%7B1%7D%2C+%7B%5Ccdots%7D%2C+y_%7Bn%7D+%29+) 为随机变量建模，注意 $Y$ 现在是代表了一批随机变量（想象对应一条sequence，包含了很多的token）， ![ P(Y) ](https://www.zhihu.com/equation?tex=+P%28Y%29+) 为这些随机变量的分布；
- ![E](https://www.zhihu.com/equation?tex=E) 表示边，即概率依赖关系。具体咋理解，还是要在后面结合HMM或CRF的graph具体解释。



### **有向图 vs. 无向图**

上图可以看到，贝叶斯网络（信念网络）都是有向的，马尔科夫网络无向。所以，贝叶斯网络适合为有**单向依赖**的数据建模，马尔科夫网络适合**实体之间互相依赖**的建模。具体地，他们的核心差异表现在如何求 ![P=(Y)](https://www.zhihu.com/equation?tex=P%3D%28Y%29) ，即怎么表示 ![Y=(y_{1},\cdots,y_{n})](https://www.zhihu.com/equation?tex=Y%3D%EF%BC%88y_%7B1%7D%2C%5Ccdots%2Cy_%7Bn%7D%EF%BC%89) 这个的联合概率。

**1. 有向图**

对于有向图模型，这么求联合概率：$P(x_1, \cdots, x_n ) = \prod_{i=0}P(x_i|\pi(x_i))$

举个例子，对于下面的这个有向图的随机变量(注意，这个图我画的还是比较广义的)：

![](/Users/liuxingyu/Pictures/markdown/directiongraph.jpg)

应该这样表示他们的==联合概率==:

![P(x_{1}, {\cdots}, x_{n} )=P(x_{1})·P(x_{2}|x_{1} )·P(x_{3}|x_{2} )·P(x_{4}|x_{2} )·P(x_{5}|x_{3},x_{4} ) ](https://www.zhihu.com/equation?tex=P%28x_%7B1%7D%2C+%7B%5Ccdots%7D%2C+x_%7Bn%7D+%29%3DP%28x_%7B1%7D%29%C2%B7P%28x_%7B2%7D%7Cx_%7B1%7D+%29%C2%B7P%28x_%7B3%7D%7Cx_%7B2%7D+%29%C2%B7P%28x_%7B4%7D%7Cx_%7B2%7D+%29%C2%B7P%28x_%7B5%7D%7Cx_%7B3%7D%2Cx_%7B4%7D+%29+)

​										<!--这种是有向图的概率计算方式-->



**2. 无向图**

对于无向图，我看资料一般就指马尔科夫网络(注意，这个图我画的也是比较广义的)。

![](/Users/liuxingyu/Pictures/markdown/Diregraph.jpg)

如果一个graph太大，可以用因子分解将 ![P=(Y)](https://www.zhihu.com/equation?tex=P%3D%28Y%29) 写为若干个联合概率的乘积。咋分解呢，将一个图分为若干个“小团”，注意每个团必须是“最大团”（就是==里面任何两个点连在了一块==，具体……算了不解释，有点“最大连通子图”（<!--每两点都是联通的-->）的感觉），则有：

![P(Y )=\frac{1}{Z(x)} \prod_{c}\psi_{c}(Y_{c} ) ](https://www.zhihu.com/equation?tex=P%28Y+%29%3D%5Cfrac%7B1%7D%7BZ%28x%29%7D+%5Cprod_%7Bc%7D%5Cpsi_%7Bc%7D%28Y_%7Bc%7D+%29+)

, 其中 ![Z(x) = \sum_{Y} \prod_{c}\psi_{c}(Y_{c} )](https://www.zhihu.com/equation?tex=Z%28x%29+%3D+%5Csum_%7BY%7D+%5Cprod_%7Bc%7D%5Cpsi_%7Bc%7D%28Y_%7Bc%7D+%29) ，归一化是为了让结果算作概率。<!--难-->

所以像上面的无向图：

![P(Y )=\frac{1}{Z(x)} ( \psi_{1}(X_{1}, X_{3}, X_{4} ) · \psi_{2}(X_{2}, X_{3}, X_{4} ) )](https://www.zhihu.com/equation?tex=P%28Y+%29%3D%5Cfrac%7B1%7D%7BZ%28x%29%7D+%28+%5Cpsi_%7B1%7D%28X_%7B1%7D%2C+X_%7B3%7D%2C+X_%7B4%7D+%29+%C2%B7+%5Cpsi_%7B2%7D%28X_%7B2%7D%2C+X_%7B3%7D%2C+X_%7B4%7D+%29+%29)

其中， ![ \psi_{c}(Y_{c} )](https://www.zhihu.com/equation?tex=+%5Cpsi_%7Bc%7D%28Y_%7Bc%7D+%29) 是一个最大团 ![C](https://www.zhihu.com/equation?tex=C) 上随机变量们的联合概率，一般取指数函数的：

![\psi_{c}(Y_{c} ) = e^{-E(Y_{c})} =e^{\sum_{k}\lambda_{k}f_{k}(c,y|c,x)}](https://www.zhihu.com/equation?tex=%5Cpsi_%7Bc%7D%28Y_%7Bc%7D+%29+%3D+e%5E%7B-E%28Y_%7Bc%7D%29%7D+%3De%5E%7B%5Csum_%7Bk%7D%5Clambda_%7Bk%7Df_%7Bk%7D%28c%2Cy%7Cc%2Cx%29%7D)

好了，管这个东西叫做`势函数`。注意 ![e^{\sum_{k}\lambda_{k}f_{k}(c,y|c,x)}](https://www.zhihu.com/equation?tex=e%5E%7B%5Csum_%7Bk%7D%5Clambda_%7Bk%7Df_%7Bk%7D%28c%2Cy%7Cc%2Cx%29%7D) 是否有看到CRF的影子。

那么概率无向图的联合概率分布可以在因子分解下表示为：

![P(Y )=\frac{1}{Z(x)} \prod_{c}\psi_{c}(Y_{c} ) = \frac{1}{Z(x)} \prod_{c} e^{\sum_{k}\lambda_{k}f_{k}(c,y|c,x)} = \frac{1}{Z(x)} e^{\sum_{c}\sum_{k}\lambda_{k}f_{k}(y_{i},y_{i-1},x,i)}](https://www.zhihu.com/equation?tex=P%28Y+%29%3D%5Cfrac%7B1%7D%7BZ%28x%29%7D+%5Cprod_%7Bc%7D%5Cpsi_%7Bc%7D%28Y_%7Bc%7D+%29+%3D+%5Cfrac%7B1%7D%7BZ%28x%29%7D+%5Cprod_%7Bc%7D+e%5E%7B%5Csum_%7Bk%7D%5Clambda_%7Bk%7Df_%7Bk%7D%28c%2Cy%7Cc%2Cx%29%7D+%3D+%5Cfrac%7B1%7D%7BZ%28x%29%7D+e%5E%7B%5Csum_%7Bc%7D%5Csum_%7Bk%7D%5Clambda_%7Bk%7Df_%7Bk%7D%28y_%7Bi%7D%2Cy_%7Bi-1%7D%2Cx%2Ci%29%7D)

注意，这里的理解还蛮重要的，注意递推过程，敲黑板，这是CRF的开端！
这个由`Hammersly-Clifford law`保证，具体不展开。

## 